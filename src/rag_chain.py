import os
from dotenv import load_dotenv
from langchain_community.vectorstores import Qdrant
from langchain_community.embeddings import HuggingFaceEmbeddings
from qdrant_client import QdrantClient
from qdrant_client.http.models import Filter, FieldCondition, MatchValue
import logging

# Load environment variables
load_dotenv()
QDRANT_URL = os.getenv("QDRANT_URL")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")

COLLECTION_QUESTIONS = "vimedical-questions"
COLLECTION_INFORMATION = "vimedical-information"

if not QDRANT_URL or not QDRANT_API_KEY:
    raise ValueError("‚ö†Ô∏è Thi·∫øu QDRANT_URL ho·∫∑c QDRANT_API_KEY trong file .env")

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# H√†m chu·∫©n h√≥a t√™n b·ªánh (gi·ªëng v·ªõi create_index.py)
def normalize_disease_name(disease_name):
    # Lo·∫°i b·ªè d·∫•u c√°ch th·ª´a
    normalized = disease_name.strip().replace("  ", " ")
    
    # Vi·∫øt hoa ch·ªØ ƒë·∫ßu m·ªói t·ª´
    normalized = " ".join(word.capitalize() for word in normalized.split())
    return normalized

# Kh·ªüi t·∫°o c√°c vectorstore t·ª´ Qdrant Cloud
def load_vectorstores():
    try:
        client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)
        embedding = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

        questions_vs = Qdrant(
            client=client,
            collection_name=COLLECTION_QUESTIONS,
            embeddings=embedding,
            content_payload_key="text",
            metadata_payload_key="metadata"
        )

        information_vs = Qdrant(
            client=client,
            collection_name=COLLECTION_INFORMATION,
            embeddings=embedding,
            content_payload_key="text",
            metadata_payload_key="metadata"
        )

        logger.info("‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng vectorstores t·ª´ Qdrant")
        return questions_vs, information_vs
    except Exception as e:
        logger.error(f"‚ùå L·ªói khi t·∫£i vectorstores: {e}")
        raise

# T·∫°o RAG Chain v·ªõi 2 b∆∞·ªõc truy v·∫•n
def get_qa_chain(memory=None):
    questions_vs, information_vs = load_vectorstores()

    def run(query, use_memory=False):
        try:
            # N·∫øu use_memory=True, truy xu·∫•t t√™n b·ªánh t·ª´ b·ªô nh·ªõ
            if use_memory and memory:
                disease_name = memory.get("last_disease", None)
                if not disease_name:
                    logger.warning("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y t√™n b·ªánh trong b·ªô nh·ªõ.")
                    return {
                        "result": "T√¥i kh√¥ng nh·ªõ b·ªánh n√†o ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p tr∆∞·ªõc ƒë√≥. Vui l√≤ng cung c·∫•p th√™m th√¥ng tin ho·∫∑c h·ªèi l·∫°i v·ªÅ tri·ªáu ch·ª©ng.",
                        "disease": "",
                        "context": "",
                        "source_documents": []
                    }
                disease_name = normalize_disease_name(disease_name)
                logger.info(f"üîç S·ª≠ d·ª•ng t√™n b·ªánh t·ª´ b·ªô nh·ªõ: {disease_name}")

            else:
                # B∆∞·ªõc 1: Truy xu·∫•t c√¢u h·ªèi g·∫ßn nh·∫•t ƒë·ªÉ l·∫•y metadata b·ªánh
                question_retriever = questions_vs.as_retriever(search_kwargs={"k": 1})
                question_docs = question_retriever.invoke(query)

                if not question_docs:
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y c√¢u h·ªèi t∆∞∆°ng t·ª± cho: {query}")
                    return {
                        "result": "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin li√™n quan trong t√†i li·ªáu y t·∫ø hi·ªán c√≥.",
                        "disease": "",
                        "context": "",
                        "source_documents": []
                    }

                # Truy xu·∫•t disease t·ª´ metadata v√† chu·∫©n h√≥a
                disease_name = question_docs[0].metadata.get("disease", "").strip()
                if not disease_name:
                    logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y t√™n b·ªánh trong metadata: {question_docs[0].metadata}")
                    return {
                        "result": "Kh√¥ng th·ªÉ x√°c ƒë·ªãnh t√™n b·ªánh t·ª´ c√¢u h·ªèi t∆∞∆°ng t·ª±.",
                        "disease": "",
                        "context": "",
                        "source_documents": []
                    }

                # Chu·∫©n h√≥a t√™n b·ªánh
                disease_name = normalize_disease_name(disease_name)
                logger.info(f"üîç T√™n b·ªánh t√¨m ƒë∆∞·ª£c: {disease_name}")

                # L∆∞u t√™n b·ªánh v√†o b·ªô nh·ªõ
                if memory:
                    memory["last_disease"] = disease_name
                    logger.info(f"üíæ ƒê√£ l∆∞u t√™n b·ªánh v√†o b·ªô nh·ªõ: {disease_name}")

            # B∆∞·ªõc 2: Truy xu·∫•t th√¥ng tin li√™n quan t·ªõi b·ªánh ƒë√≥
            filter_condition = Filter(
                must=[FieldCondition(key="metadata.disease", match=MatchValue(value=disease_name))]
            )
            info_retriever = information_vs.as_retriever(
                search_kwargs={"k": 4, "filter": filter_condition}
            )
            info_docs = info_retriever.invoke(query if not use_memory else disease_name)

            if not info_docs:
                logger.warning(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y th√¥ng tin chi ti·∫øt cho b·ªánh: {disease_name}")
                return {
                    "result": f"D·ª±a tr√™n tri·ªáu ch·ª©ng b·∫°n m√¥ t·∫£, b·∫°n c√≥ th·ªÉ ƒëang g·∫∑p ph·∫£i {disease_name}. T√¥i khuy√™n b·∫°n n√™n ƒëi kh√°m b√°c sƒ© ƒë·ªÉ ƒë∆∞·ª£c ch·∫©n ƒëo√°n v√† ƒëi·ªÅu tr·ªã ch√≠nh x√°c.",
                    "disease": disease_name,
                    "context": "",
                    "source_documents": [{"content": doc.page_content, "metadata": doc.metadata} for doc in question_docs] if not use_memory else []
                }

            context = "\n\n".join([doc.page_content for doc in info_docs])
            return {
                "context": context,
                "disease": disease_name,
                "source_documents": [{"content": doc.page_content, "metadata": doc.metadata} for doc in info_docs]
            }

        except Exception as e:
            logger.error(f"‚ùå L·ªói trong qu√° tr√¨nh truy v·∫•n: {e}")
            return {
                "result": f"ƒê√£ x·∫£y ra l·ªói trong qu√° tr√¨nh truy v·∫•n: {str(e)}",
                "disease": "",
                "context": "",
                "source_documents": []
            }

    return run